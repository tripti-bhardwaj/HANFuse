{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11a46173",
   "metadata": {
    "id": "11a46173"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD  \n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import hstack\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ebde7",
   "metadata": {
    "id": "902ebde7"
   },
   "source": [
    "#### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3419d51c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3419d51c",
    "outputId": "6593db6f-a431-4df7-a66f-51d8c13a5755",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (60000, 6)  Dev: (20000, 6)  Test: (20000, 6)\n",
      "            id                                               text        user  \\\n",
      "37708  45353.0  @USER @USER @USER @USER সাদা উদারপন্থী do not ...       ann87   \n",
      "11367  90011.0                        @USER ভাই...সে है cray mehn  jennifer55   \n",
      "7410       NaN  @USER @USER @USER @USER @USER @USER यह एंटीफा ...         NaN   \n",
      "26700  27255.0             @USER कर सकना আপনি say DESPERATE?!?!?!       sam42   \n",
      "57749  52628.0     @USER I’ll যাওয়া चुनना u up लानत है একটি उबेर     steve11   \n",
      "\n",
      "      state      time  label  \n",
      "37708    CT  12:09:07      0  \n",
      "11367    FL   1:39:29      0  \n",
      "7410    NaN       NaN      1  \n",
      "26700    NY   0:22:52      0  \n",
      "57749    VA  17:57:49      1               id                                               text        user  \\\n",
      "12041  16051.0                       @USER Exactly... वे সব कड़वा  jennifer55   \n",
      "18558      NaN  .@USER है her own ব্যক্তি সে এটি না a @USER नक...         NaN   \n",
      "8492   49300.0  @USER Well your a उदारवादियों के लिए उपकरण তাই...    george45   \n",
      "12707  92046.0  @USER @USER हां मूल रूप से another মৃত বিড়াল URL      matt31   \n",
      "17925  49189.0  @USER @USER Agree 100% Jay No wonder FBI बैकबर...    george45   \n",
      "\n",
      "      state      time  label  \n",
      "12041    DE  14:50:13      1  \n",
      "18558   NaN       NaN      0  \n",
      "8492     FL  23:09:51      0  \n",
      "12707    CT   2:47:24      0  \n",
      "17925    NY   0:58:38      0               id                                               text        user  \\\n",
      "17270  54521.0  @USER আমাদের দেশ কি পারবে? अपने कानून प्रवर्तन...      matt31   \n",
      "5301   75579.0                         @USER बहुत अच्छा সেক্সি❤😍👌       ann87   \n",
      "145    70822.0                                @USER वह is एक দানব      matt31   \n",
      "735    56141.0  @USER नहीं करता है seem like হলিউডে আছে অনেক ব...  jennifer55   \n",
      "1769   97312.0  যদি আমাকে করতে হয় tolerate ur loud ass मैगा म...  jennifer55   \n",
      "\n",
      "      state      time  label  \n",
      "17270    VA   7:19:36      0  \n",
      "5301     DE  23:03:42      0  \n",
      "145      NY  19:38:24      1  \n",
      "735      FL  15:05:54      0  \n",
      "1769     DE   5:38:17      1  \n"
     ]
    }
   ],
   "source": [
    "df_tr = pd.read_csv(\"/Users/triptibhardwaj/Downloads/train.csv\")\n",
    "df_va = pd.read_csv(\"/Users/triptibhardwaj/Downloads/dev.csv\")\n",
    "df_te = pd.read_csv(\"/Users/triptibhardwaj/Downloads/test.csv\")\n",
    "\n",
    "label_map = {\"OFF\": 1, \"NOT\": 0}\n",
    "df_tr[\"label\"] = df_tr[\"label\"].map(label_map)\n",
    "df_va[\"label\"] = df_va[\"label\"].map(label_map)\n",
    "df_te[\"label\"] = df_te[\"label\"].map(label_map)\n",
    "\n",
    "print(\"Train:\", df_tr.shape, \" Dev:\", df_va.shape, \" Test:\", df_te.shape)\n",
    "print(df_tr.sample(5), df_va.sample(5), df_te.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d71c571",
   "metadata": {
    "id": "2d71c571"
   },
   "source": [
    "#### PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39606f13",
   "metadata": {
    "id": "39606f13"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        self.texts = df[\"text\"].tolist()\n",
    "        self.labels = df[\"label\"].tolist()\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.texts[idx].split()\n",
    "        ids = [self.vocab.get(tok, 1) for tok in tokens]  # unk=1\n",
    "        return {\n",
    "            \"doc_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"y_off\": torch.tensor(self.labels[idx], dtype=torch.float32),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6075156a",
   "metadata": {
    "id": "6075156a"
   },
   "source": [
    "#### HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84560821",
   "metadata": {
    "id": "84560821"
   },
   "outputs": [],
   "source": [
    "class WordAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attn = nn.Linear(2*hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embed(x)  # [B, W, E]\n",
    "        h, _ = self.rnn(emb) # [B, W, 2H]\n",
    "        a = torch.softmax(self.attn(h), dim=1) # [B, W, 1]\n",
    "        rep = (a * h).sum(dim=1)               # [B, 2H]\n",
    "        return rep\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=100, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.word_encoder = WordAttention(vocab_size, emb_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, doc_ids):\n",
    "        return self.word_encoder(doc_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc94d3",
   "metadata": {
    "id": "53dc94d3"
   },
   "source": [
    "#### Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1af53c0",
   "metadata": {
    "id": "b1af53c0"
   },
   "outputs": [],
   "source": [
    "class FusionHANModel(nn.Module):\n",
    "    def __init__(self, vocab_size, tfidf_dim, emb_dim=100, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.han = HAN(vocab_size, emb_dim, hidden_dim)\n",
    "        self.fc_off = nn.Linear(2*hidden_dim + tfidf_dim, 1)\n",
    "\n",
    "    def forward(self, doc_ids, feats):\n",
    "        han_vec = self.han(doc_ids)\n",
    "        x = torch.cat([han_vec, feats], dim=1)\n",
    "        return {\"offense\": self.fc_off(x).squeeze(1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b254223",
   "metadata": {
    "id": "7b254223"
   },
   "source": [
    "#### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab76a4cf",
   "metadata": {
    "id": "ab76a4cf"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, device=\"cpu\"):\n",
    "        self.model = model.to(device)\n",
    "        self.opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        self.device = device\n",
    "\n",
    "    def step_batch(self, batch, feats):\n",
    "        self.model.train()\n",
    "        self.opt.zero_grad()\n",
    "        out = self.model(batch[\"doc_ids\"].to(self.device), feats.to(self.device))\n",
    "        loss = F.binary_cross_entropy_with_logits(out[\"offense\"], batch[\"y_off\"].to(self.device))\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "\n",
    "    def evaluate(self, loader, feats):\n",
    "        self.model.eval()\n",
    "        ys, yh = [], []\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(loader):\n",
    "                f = feats[i*batch_size:(i+1)*batch_size]\n",
    "                out = self.model(batch[\"doc_ids\"].to(self.device), f.to(self.device))\n",
    "                yh.extend(torch.sigmoid(out[\"offense\"]).cpu().numpy() > 0.5)\n",
    "                ys.extend(batch[\"y_off\"].numpy())\n",
    "        print(classification_report(ys, yh, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0672be7",
   "metadata": {
    "id": "e0672be7"
   },
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76ae6c3",
   "metadata": {
    "id": "b76ae6c3"
   },
   "outputs": [],
   "source": [
    "def train_model(trainer, train_loader, dev_loader, Xtr, Xva, num_epochs=10, batch_size=32):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            f = torch.tensor(Xtr[i*batch_size:(i+1)*batch_size], dtype=torch.float32)\n",
    "            trainer.step_batch(batch, f)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} completed.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5956441a",
   "metadata": {
    "id": "5956441a"
   },
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b964a9bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b964a9bf",
    "outputId": "dfde8c05-27d8-4d7f-d96f-8d9fd53d5d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 completed.\n",
      "Epoch 2/10 completed.\n",
      "Epoch 3/10 completed.\n",
      "Epoch 4/10 completed.\n",
      "Epoch 5/10 completed.\n",
      "Epoch 6/10 completed.\n",
      "Epoch 7/10 completed.\n",
      "Epoch 8/10 completed.\n",
      "Epoch 9/10 completed.\n",
      "Epoch 10/10 completed.\n",
      "\n",
      "=== Final Test Evaluation ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.939     0.929     0.934     13340\n",
      "         1.0      0.861     0.878     0.869      6660\n",
      "\n",
      "    accuracy                          0.912     20000\n",
      "   macro avg      0.900     0.904     0.902     20000\n",
      "weighted avg      0.913     0.912     0.912     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Vocabulary\n",
    "    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "    for sent in df_tr[\"text\"]:\n",
    "        for tok in sent.split():\n",
    "            if tok not in vocab:\n",
    "                vocab[tok] = len(vocab)\n",
    "\n",
    "    # TF-IDF\n",
    "    tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "    tfidf.fit(df_tr[\"text\"])\n",
    "    Xtr = tfidf.transform(df_tr[\"text\"]).toarray()\n",
    "    Xva = tfidf.transform(df_va[\"text\"]).toarray()\n",
    "    Xte = tfidf.transform(df_te[\"text\"]).toarray()\n",
    "\n",
    "    # Datasets + Loaders\n",
    "    train_set = TextDataset(df_tr, vocab)\n",
    "    dev_set   = TextDataset(df_va, vocab)\n",
    "    test_set  = TextDataset(df_te, vocab)\n",
    "\n",
    "    global batch_size\n",
    "    batch_size = 32\n",
    "    tr_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=lambda x: {\n",
    "        \"doc_ids\": nn.utils.rnn.pad_sequence([item[\"doc_ids\"] for item in x], batch_first=True),\n",
    "        \"y_off\": torch.stack([item[\"y_off\"] for item in x])\n",
    "    })\n",
    "    va_loader = DataLoader(dev_set, batch_size=batch_size, shuffle=False, collate_fn=lambda x: {\n",
    "        \"doc_ids\": nn.utils.rnn.pad_sequence([item[\"doc_ids\"] for item in x], batch_first=True),\n",
    "        \"y_off\": torch.stack([item[\"y_off\"] for item in x])\n",
    "    })\n",
    "    te_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=lambda x: {\n",
    "        \"doc_ids\": nn.utils.rnn.pad_sequence([item[\"doc_ids\"] for item in x], batch_first=True),\n",
    "        \"y_off\": torch.stack([item[\"y_off\"] for item in x])\n",
    "    })\n",
    "\n",
    "    # Model + Trainer\n",
    "    model = FusionHANModel(len(vocab), tfidf_dim=5000)\n",
    "    trainer = Trainer(model, device=\"cpu\")\n",
    "\n",
    "    # Train\n",
    "    train_model(trainer, tr_loader, va_loader, Xtr, Xva, num_epochs=10, batch_size=batch_size)\n",
    "\n",
    "    # Final Test\n",
    "    print(\"\\n=== Final Test Evaluation ===\")\n",
    "    trainer.evaluate(te_loader, torch.tensor(Xte, dtype=torch.float32))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
